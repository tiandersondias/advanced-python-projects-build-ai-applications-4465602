{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363bf99c",
   "metadata": {
    "id": "363bf99c"
   },
   "source": [
    "## Installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fd8174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (1.6.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement matlotlib (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for matlotlib\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn matlotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08081f18",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1709836774197,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "08081f18"
   },
   "outputs": [],
   "source": [
    "#import all of the required libraries and classes right here\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac620e",
   "metadata": {
    "id": "85ac620e"
   },
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0961b773",
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1709836775020,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "0961b773"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Coffee Shop data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/advanced-python-projects-build-ai-applications-4465602/Begin/CH_2_Business_Prediction.ipynb CÃ©lula 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Borganic-disco-7wv9xxjgqrq3ww64/workspaces/advanced-python-projects-build-ai-applications-4465602/Begin/CH_2_Business_Prediction.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_excel(\u001b[39m'\u001b[39;49m\u001b[39mCoffee Shop data.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Borganic-disco-7wv9xxjgqrq3ww64/workspaces/advanced-python-projects-build-ai-applications-4465602/Begin/CH_2_Business_Prediction.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m population\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mpopulation.csv\u001b[39m\u001b[39m'\u001b[39m,skiprows\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(\n\u001b[1;32m    496\u001b[0m         io,\n\u001b[1;32m    497\u001b[0m         storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    498\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    499\u001b[0m         engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1551\u001b[0m         content_or_path\u001b[39m=\u001b[39;49mpath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m   1552\u001b[0m     )\n\u001b[1;32m   1553\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(content_or_path, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[39m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1403\u001b[0m     content_or_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m ) \u001b[39mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Coffee Shop data.xlsx'"
     ]
    }
   ],
   "source": [
    "df=pd.read_excel('CH_2_Coffee Shop data.xlsx')\n",
    "population=pd.read_csv('population.csv',skiprows=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60162560",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1709836775020,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "60162560",
    "outputId": "017aa4c8-79c7-4744-ce2b-f2e8e4e6e95e"
   },
   "outputs": [],
   "source": [
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4048b6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1709836775020,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "b4048b6b",
    "outputId": "ab86eb91-7562-4e54-873f-01f9f498e9f8"
   },
   "outputs": [],
   "source": [
    "df.head()#checking first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e8131",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1709836775021,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "159e8131",
    "outputId": "5b973ca1-375d-4a4b-964d-55b5c821d98d"
   },
   "outputs": [],
   "source": [
    "# check for data info\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd613c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1709836775021,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "fadd613c",
    "outputId": "e18c28b2-41fb-4c66-ee2f-572ef4623d2d"
   },
   "outputs": [],
   "source": [
    "#check the number of records and features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f41ea9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1709836775021,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "38f41ea9",
    "outputId": "10beb0e0-9e18-4297-a7d0-1203385f10e3"
   },
   "outputs": [],
   "source": [
    "population.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590d579",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1709836775021,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "5590d579",
    "outputId": "670ef3c9-3bc2-4335-bb23-9ab8b7cc399f"
   },
   "outputs": [],
   "source": [
    "# get basic stats about the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdde9c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1709836775451,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "2cdde9c6",
    "outputId": "f45f5b65-9abf-4995-f29f-7f4be0123a27"
   },
   "outputs": [],
   "source": [
    "ax=df['City'].value_counts().head(5).plot(kind='bar')\n",
    "ax.set_title('Top 5 cities with most cofee shops')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1c1d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1709836775759,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "57d1c1d5",
    "outputId": "484c78f7-92d4-4ecb-ed54-9a88dee76369"
   },
   "outputs": [],
   "source": [
    "ax=df['Business Name'].value_counts().head(10).plot(kind='bar')\n",
    "ax.set_title('Top 10 most famous brands')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea26fe",
   "metadata": {
    "id": "22ea26fe"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac6d7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1709836776106,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "f9ac6d7d",
    "outputId": "bcca8809-1e3a-42e1-ce34-eb157bb36fbb"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "# no null values\n",
    "# if we have null values we would impute it. If we have numberical replace mean. Missing values - replace it with the mode (most occuring values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119ace2",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709836776106,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "b119ace2"
   },
   "outputs": [],
   "source": [
    "#converting zipcode to object data (str) - We need to join the zip code with the population data. Converting the coffee shop data. In order to store it into alphanumerical value, it should be string.\n",
    "df['Zip Code']=df['Zip Code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce458280",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709836776106,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "ce458280"
   },
   "outputs": [],
   "source": [
    "#extract zip code from population\n",
    "# Find all of the zipcode that has a 5 digit pattern. Getting the last 5 digits from the population zip code. Creating a new column called zip code\n",
    "\n",
    "def find_zip_code(geocode):\n",
    "    pattern = r'\\d{5}$'\n",
    "\n",
    "    match = re.search(pattern, geocode)\n",
    "\n",
    "    if match:\n",
    "        zip_code = match.group(0)\n",
    "    return zip_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38881b0b",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709836776106,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "38881b0b"
   },
   "outputs": [],
   "source": [
    "# The actual coversion is below. The above is the function\n",
    "\n",
    "population['Zip Code']=population['Geography'].apply(find_zip_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22bb57",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709836776107,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "1b22bb57"
   },
   "outputs": [],
   "source": [
    "cafe_data=df.copy()\n",
    "# merging the population via zip code as population is an important feature to determing the price / locations\n",
    "df=pd.merge(cafe_data,population)\n",
    "#notice that the data size is reduced afer a join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102897f",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709836776107,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "1102897f"
   },
   "outputs": [],
   "source": [
    "#keeping only Total from population. In the pop dataset, keeping total population column and other columns.\n",
    "columns=cafe_data.columns.values.tolist()+['Total']\n",
    "df=df[columns]\n",
    "#rename Total to Population\n",
    "df=df.rename(columns={\"Total\":\"Population\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a796f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270e1ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709836776107,
     "user": {
      "displayName": "Priya Mohan",
      "userId": "10194897099303360694"
     },
     "user_tz": 300
    },
    "id": "9270e1ca",
    "outputId": "999db953-db2b-42b7-de5b-4a413050f02c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keeping only relevant features\n",
    "df= df[['Zip Code','Rating','Median Salary','Latte Price','Population']]\n",
    "#df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of coffee shops for each zip code\n",
    "coffee_shop_counts = df['Zip Code'].value_counts().reset_index()\n",
    "coffee_shop_counts.columns = ['Zip Code', 'CoffeeShopCount']\n",
    "\n",
    "# Ensure 'Zip Code' is of type string in both DataFrames\n",
    "df['Zip Code'] = df['Zip Code'].astype(str)\n",
    "coffee_shop_counts['Zip Code'] = coffee_shop_counts['Zip Code'].astype(str)\n",
    "\n",
    "# Merge the counts back into the original DataFrame\n",
    "df = df.merge(coffee_shop_counts, on='Zip Code', how='left')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n",
    "\n",
    "# Criteria:\n",
    "# a. High population\n",
    "# b. Low total number of coffee shops\n",
    "# c. Low ratings\n",
    "# d. High median salary\n",
    "\n",
    "# Sorting the DataFrame based on the criteria\n",
    "sorted_df = df.sort_values(by=['Population', 'CoffeeShopCount', 'Rating', 'Median Salary'],\n",
    "                           ascending=[False, True, True, False]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a list - if length of list 5, if the zip code is already present, it will not add that into the list. \n",
    "# Deduping zip code column and displaying all of the records for the top 5.\n",
    "lst=[]\n",
    "for i in range(len(sorted_df)):\n",
    "    if len(lst)!=5:\n",
    "        if (sorted_df['Zip Code'][i]) not in lst:\n",
    "            lst.append(sorted_df['Zip Code'][i])\n",
    "            \n",
    "# Filter 'sorted_df' to include only rows where 'Zip Code' is in 'lst'\n",
    "top_5_zip_codes_df = sorted_df[sorted_df['Zip Code'].isin(lst)]\n",
    "\n",
    "top_5_zip_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29329ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Latte Price', 'Zip Code'], axis=1)  # Features excluding 'Latte Price' and 'Zip Code'\n",
    "y = df['Latte Price']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80681397",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddbd359",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Selection\n",
    "models = {\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c80511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'Gradient Boosting': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 10]},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    if model_name in param_grid:\n",
    "        # Perform hyperparameter tuning using GridSearchCV\n",
    "        grid_search = GridSearchCV(model, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        # Set the best hyperparameters to the model\n",
    "        models[model_name] = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0ec53",
   "metadata": {},
   "source": [
    "Model Trainin and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77649861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d643968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "for model_name, model in models.items():\n",
    "    # Evaluate the model on the testing set\n",
    "    y_pred = \n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "    print(\"R-squared:\", r2_score(y_test, y_pred))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae165610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want this dataframe to be same as the training data so that model can predict the value\n",
    "zip_codes_df= top_5_zip_codes_df.drop(['Zip Code', 'Latte Price'], axis=1)\n",
    "zip_codes_df= sc.transform(zip_codes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    # Predict the prices for lattes in the top 5 zip codes\n",
    "    predicted_prices = model.predict(zip_codes_df)\n",
    "    print(f\"{model_name} Predicted Prices for Top 5 Zip Codes:\")\n",
    "    print(predicted_prices)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Predict the prices for lattes in the top 5 zip codes\n",
    "    predicted_prices = model.predict(zip_codes_df)\n",
    "    predictions[model_name] = predicted_prices\n",
    "\n",
    "# Convert the predictions dictionary to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "# Add the zip codes to the predictions DataFrame\n",
    "predictions_df['Zip Code'] = top_5_zip_codes_df['Zip Code'].values\n",
    "\n",
    "# Rearrange the columns to have 'Zip Code' as the first column\n",
    "cols = ['Zip Code'] + [col for col in predictions_df.columns if col != 'Zip Code']\n",
    "predictions_df = predictions_df[cols]\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5892b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = predictions_df.groupby('Zip Code')['Gradient Boosting'].agg([(\"Highest\", \"max\"), (\"Lowest\", \"min\")]).reset_index()\n",
    "agg_df.columns = ['Zip Code', 'Highest', 'Lowest']\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27956af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
